#!/bin/bash
#SBATCH --account=liu32_1378
#SBATCH --partition=gpu
#SBATCH --nodes=1
#SBATCH --ntasks=1

# ============================================================================
# GRPO æ¨¡å‹æ¨ç†è¯„ä¼°èµ„æºé…ç½®
# ============================================================================
# æ•°æ®é›†å¤§å° | æ ·æœ¬æ•° | æ—¶é—´       | å†…å­˜  | CPU | GPU | è¯´æ˜
# -----------|--------|-----------|-------|-----|-----|------------------
# å¿«é€Ÿæµ‹è¯•   | 10     | 00:15:00  | 16G   | 4   | 1   | éªŒè¯æ¨¡å‹åŠ è½½å’Œæ¨ç†
# å®Œæ•´è¯„ä¼°   | 395    | 00:30:00  | 24G   | 8   | 1   | å®Œæ•´æµ‹è¯•é›†è¯„ä¼°
# ============================================================================

# ============================================================================
# GPU ç­–ç•¥ï¼šä¸æŒ‡å®šå‹å· = æ¥å—æ‰€æœ‰å¯ç”¨ GPUï¼ˆL40S/A100/A40/V100ï¼‰
# ä¼˜ç‚¹ï¼šå¤§å¤§æé«˜è·å¾—èµ„æºé€Ÿåº¦ï¼Œå‡å°‘æ’é˜Ÿæ—¶é—´
# æ³¨æ„ï¼šç³»ç»Ÿå¯èƒ½åˆ†é… P100ï¼ˆCUDA 6.0ï¼‰ï¼Œä»£ç ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶æŠ¥è­¦
# ============================================================================
# å¯ç”¨ GPU å‹å·ï¼ˆæŒ‰æ€§èƒ½æ’åºï¼‰ï¼š
#   l40s (CUDA 8.9) > a100 (CUDA 8.0) > a40 (CUDA 8.6) > v100 (CUDA 7.0)
#   âš ï¸ p100 (CUDA 6.0) ä¸å…¼å®¹ PyTorch 2.8+
# 
# æ¨ç†ä»»åŠ¡ç‰¹ç‚¹ï¼š
#   - ç›¸æ¯”è®­ç»ƒï¼Œæ¨ç†å¯¹GPUæ€§èƒ½è¦æ±‚æ›´ä½
#   - V100/A40 å·²ç»è¶³å¤Ÿå¿«
#   - å»ºè®®ä¸æŒ‡å®šGPUå‹å·ï¼ŒåŠ å¿«æ’é˜Ÿé€Ÿåº¦
# ============================================================================

# ============================================================================
# æ–¹æ¡ˆAï¼šå¿«é€Ÿæµ‹è¯•é…ç½®ï¼ˆ10æ¡æ ·æœ¬ï¼‰- å½“å‰é»˜è®¤
# ç”¨é€”ï¼šéªŒè¯ GRPO æ¨¡å‹åŠ è½½ã€æ¨ç†æµç¨‹ã€ç»“æœä¿å­˜
# æ•°æ®ï¼štrain[924:934]ï¼ˆä»£ç é»˜è®¤ï¼‰
# ============================================================================
# #SBATCH --cpus-per-task=4
# #SBATCH --mem=16G
# #SBATCH --time=00:15:00
# #SBATCH --gpus-per-task=1

# ============================================================================
# æ–¹æ¡ˆBï¼šå®Œæ•´è¯„ä¼°é…ç½®ï¼ˆ395æ¡æ ·æœ¬ï¼‰
# ç”¨é€”ï¼šå®Œæ•´æµ‹è¯•é›†è¯„ä¼°ï¼Œè·å¾—å‡†ç¡®çš„ accuracy æŒ‡æ ‡
# æ•°æ®ï¼štrain[924:1319]ï¼ˆéœ€è¦ä¿®æ”¹ä»£ç ç¬¬45è¡Œï¼‰
# ä½¿ç”¨æ–¹æ³•ï¼šæ³¨é‡Šæ‰ä¸Šæ–¹æ–¹æ¡ˆAçš„4è¡Œï¼Œå–æ¶ˆä¸‹æ–¹4è¡Œçš„æ³¨é‡Š
# ============================================================================
#SBATCH --cpus-per-task=8
#SBATCH --mem=24G
#SBATCH --time=12:30:00
#SBATCH --gpus-per-task=1

# ============================================================================
# é‚®ä»¶é€šçŸ¥é…ç½®
# ============================================================================
#SBATCH --mail-user=yihelu@usc.edu
#SBATCH --mail-type=END,FAIL

# ============================================================================
# å¦‚æœæ’é˜Ÿå¤ªä¹…ï¼Œå¯å–æ¶ˆä»¥ä¸‹æ³¨é‡ŠæŒ‡å®šç‰¹å®šGPUå‹å·ï¼š
# #SBATCH --gpus-per-task=v100:1    # æ¨èï¼šæ€§èƒ½å¤Ÿç”¨ï¼Œèµ„æºå……è¶³
# #SBATCH --gpus-per-task=a40:1     # å¤‡é€‰ï¼šæ€§èƒ½å¼ºï¼Œèµ„æºç›¸å¯¹å……è¶³
# SBATCH --gpus-per-task=a100:1    # é«˜æ€§èƒ½ä½†æ’é˜Ÿé•¿
# #SBATCH --gpus-per-task=l40s:1    # æœ€å¼ºä½†æ’é˜Ÿæœ€é•¿
# ============================================================================

echo ""
echo "=========================================="
echo "ğŸš€ GRPO Model Inference Job Starting"
echo "=========================================="
echo "Job started at: `date`"
echo "Running on hosts: $SLURM_NODELIST"
echo "Running on $SLURM_NNODES nodes"
echo "Running on $SLURM_NPROCS processors"
echo "GPU allocation: $CUDA_VISIBLE_DEVICES"
echo "=========================================="
echo ""

# Move to the correct directory
cd /home1/yihelu/csci566/
echo "Current working directory: `pwd`"

# Load conda environment
source /apps/conda/miniforge3/24.3.0/etc/profile.d/conda.sh
conda activate torch-env

# ============================================================================
# è¿è¡Œ GRPO æ¨¡å‹æ¨ç†è¯„ä¼°
# ============================================================================
# 
# è„šæœ¬åŠŸèƒ½ï¼š
#   1. åŠ è½½ GRPO è®­ç»ƒçš„ LoRA æ¨¡å‹ï¼ˆqwen_grpo_lora_multigpuï¼‰
#   2. åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæ¨ç†ï¼ˆtrain[924:934] æˆ– train[924:1319]ï¼‰
#   3. è®¡ç®— accuracy å¹¶ä¿å­˜è¯¦ç»†ç»“æœ
#   4. è¾“å‡ºç›®å½•ï¼šinference_results_grpo/
# 
# è¾“å‡ºæ–‡ä»¶ï¼š
#   - inference_results.json      : æ‰€æœ‰æ ·æœ¬çš„æ¨ç†ç»“æœ
#   - evaluation_metrics.json     : accuracy ç­‰è¯„ä¼°æŒ‡æ ‡
#   - wrong_cases.json            : é”™è¯¯æ¡ˆä¾‹åˆ†æ
# 
# é…ç½®åˆ‡æ¢ï¼š
#   - å½“å‰ï¼š10æ¡æµ‹è¯•ï¼ˆtrain[924:934]ï¼‰
#   - å®Œæ•´è¯„ä¼°ï¼šä¿®æ”¹ä»£ç ç¬¬45è¡Œä¸º train[924:1319]
#   - åŒæ—¶åˆ‡æ¢ SLURM é…ç½®åˆ°æ–¹æ¡ˆBï¼ˆæ›´å¤šèµ„æºï¼‰
# 
echo "ğŸ“Š Starting GRPO model inference..."
python 4-qwen-grpo-inference.py
# 
# ============================================================================

# Check exit status
EXIT_CODE=$?
echo ""
echo "=========================================="
if [ $EXIT_CODE -eq 0 ]; then
    echo "âœ… Inference completed successfully!"
    echo "ğŸ“ Results saved in: inference_results_grpo/"
else
    echo "âŒ Inference failed with exit code: $EXIT_CODE"
fi
echo "Job finished at: `date`"
echo "=========================================="
echo ""

exit $EXIT_CODE
